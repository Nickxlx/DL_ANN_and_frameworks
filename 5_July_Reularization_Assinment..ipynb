{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a22345-7d3b-4f0c-b2fb-f74f346d31ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting tensorboard<2.16,>=2.15\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.59.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Collecting keras<2.16,>=2.15.0\n",
      "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes~=0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Collecting wrapt<1.15,>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth-oauthlib<2,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.24.0-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.8/183.8 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.28.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, opt-einsum, ml-dtypes, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.24.0 google-auth-oauthlib-1.1.0 google-pasta-0.2.0 grpcio-1.59.3 keras-2.15.0 libclang-16.0.6 markdown-3.5.1 ml-dtypes-0.2.0 opt-einsum-3.3.0 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.4.0 werkzeug-3.0.1 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6427cafa-71d0-40e3-a939-3d8952c58d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58322fbf-d2f8-4b67-b448-8a383282de13",
   "metadata": {},
   "source": [
    "### Part l: Upderstanding Regularizatio.\n",
    "\n",
    "Q1. What is regularization in the context of deep learning, Why is it important.\n",
    "\n",
    "Answer--> It's a technique used to prevent overfitting and improve the generalization of neural networks.\n",
    "\n",
    "    Importance of Regularization:\n",
    "    \n",
    "    a Prevents overfitting\n",
    "    \n",
    "    b Improves Generalization\n",
    "    \n",
    "    c Reduce multicollanarity \n",
    "    \n",
    "Q2. Ek Explain the bias-variance tradeoff and how regularization helps in addressing this tradeoff.\n",
    "\n",
    " Answer--> The bias-variance tradeoff is a fundamental concept in machine learning and DL that illustrates the delicate balance between two types of error, bias and variance, which affect the predictive performance of a model.\n",
    "The goal is to find the optimal balance between bias and variance to achieve good predictive performance on unseen data.\n",
    "\n",
    "@3. Describe the concept of L1 and L2 regularization. How do they differ in terms of penalty calculation and their effects on the model.\n",
    "\n",
    "Answer--> \n",
    "\n",
    "    l1 regularization use absolute value of weights as penalty in cost function term which helps in feature selection.\n",
    "\n",
    "    l2 regularization use squre of the weights as penalty term in cost function which help to reduce overfiting of the model.\n",
    "\n",
    "@4. Discuss the role of regularization in preventing overfitting and improving the generalization of deep learning models.\n",
    "\n",
    "Answer--> Regularization acts as a form of control over a model's capacity to fit the training data. By penalizing complexity and reducing the model's tendency to overfit, it helps create models that generalize well to unseen data, making them more reliable and useful in practical applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2d3a4-d088-41a9-9eb0-107d9af46e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d35be5eb-8829-4d65-9233-85de06263b0e",
   "metadata": {},
   "source": [
    "### Part 2: Regularization Tecnique\n",
    "\n",
    "Q1. Explain Dropout regularization and how it works to reduce overfitting. Discuss the impact of Dropout on model training and inference.\n",
    "\n",
    "Answer-->In this techniqe during training it randomaly \"drop-out\" some neuron in as layer so that model can learn from all the neurons of the layer instead of relaying on some particulaer neuron.\n",
    "\n",
    "Q2. Describe the concept of Early stopping as a form of regularization. How does it help prevent overfitting during the training process.\n",
    "\n",
    "Answer--> Early stopping is a regularization technique used to prevent overfitting during the training process of a machine learning model, including deep learning models. The basic idea is to monitor the performance of the model on a validation dataset during training and stop the training process once the performance stops improving or starts to degrade. \n",
    "\n",
    "\n",
    "Q3. Explain the concept of Batch Normalization and its role as a form of regularization. How does Batch Normalization help in preventing overfitting.\n",
    "\n",
    "Answer--> Batch Normalization acts as a regularization technique by introducing noise and stabilizing the training process, thereby preventing overfitting. It helps in achieving faster convergence and enables the use of higher learning rates, leading to more robust and generalized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325f4649-ba22-41d5-800f-ddf74ec40bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7f3ce8c-799b-40eb-8177-45b983a4bd47",
   "metadata": {},
   "source": [
    "### Part 3: Applying Regularization. \n",
    "\n",
    "Q1. Implement Dropout regularization in a deep learning model using a framework of your choice. Evaluate its impact on model performance and compare it with a model without Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57a8c87-b43e-4546-a5e1-0d9f1ecb5d21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 09:32:49.017552: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-02 09:32:49.082479: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-02 09:32:49.082543: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-02 09:32:49.084064: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-02 09:32:49.093172: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-02 09:32:49.094472: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-02 09:32:50.365094: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f9aecef-a757-4d9e-b925-b5562256b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "\n",
    "dataset = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902a3640-099b-4b05-9bf2-a0c991b43de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adc19d22-3ee4-4fcb-9e55-51b6f28df679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6b5e912-f6dd-4135-a976-1a92360dde5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9ad54-1e8c-4396-8715-575689e1bef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc0512dd-1565-49c6-b83a-d51f37bce723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   MedInc      20640 non-null  float64\n",
      " 1   HouseAge    20640 non-null  float64\n",
      " 2   AveRooms    20640 non-null  float64\n",
      " 3   AveBedrms   20640 non-null  float64\n",
      " 4   Population  20640 non-null  float64\n",
      " 5   AveOccup    20640 non-null  float64\n",
      " 6   Latitude    20640 non-null  float64\n",
      " 7   Longitude   20640 non-null  float64\n",
      " 8   target      20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "## eda \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a60836-4a53-415e-b9fb-9385c250b4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9579709d-c55d-4b3e-91fe-be7c268a2ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dividing the dataframe\n",
    "\n",
    "x = df.drop(columns=\"target\")\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fea1f45-0c03-4aaa-b05d-9e9a94fbf283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a6e84-e639-4a1f-ac1f-2084d1996b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c33a94cc-4467-4671-845a-af10ba3be245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the dataset\n",
    "\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(x, y, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3274d0d3-4db5-457d-9ad6-9acb9f72181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5ffcdff-8ee8-4288-97ff-a2b7975d0c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 8)\n",
      "(11610, 8)\n",
      "(3870, 8)\n",
      "(5160, 8)\n"
     ]
    }
   ],
   "source": [
    "# shape of all data\n",
    "print(x_train_full.shape)\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c6a2e-b426-4a00-b31f-2426a04b4dc6",
   "metadata": {},
   "source": [
    "### WITHOUT DROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69935880-e0d9-4d71-b53e-d670d6c6a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating layout\n",
    "\n",
    "LAYERS1 = [tf.keras.layers.Dense(30, activation=\"relu\", input_shape = x_train.shape[1:]),\n",
    "            tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1, activation=\"linear\"), \n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18372782-b5eb-4960-a641-799f9962b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building \n",
    "\n",
    "model_no_drop = tf.keras.models.Sequential(LAYERS1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "419e9123-87ed-4a02-a025-b0f9b5698ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL COMPILATIONabs\n",
    "OPTIMIZER = \"adam\"\n",
    "LOSS = \"mae\"\n",
    "model_no_drop.compile(optimizer=OPTIMIZER,\n",
    "                     loss=LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed033818-2f15-4024-8ab9-4b4f757fbdb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                270       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 591 (2.31 KB)\n",
      "Trainable params: 591 (2.31 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_no_drop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c3e31ad-af39-41c4-af61-565c68c9580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_scaled_train = scaler.fit_transform(x_train)\n",
    "x_scaled_valid = scaler.fit_transform(x_valid)\n",
    "\n",
    "x_scaled_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbc23feb-ed36-4775-97d7-a5251c9b49d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "323/323 [==============================] - 2s 2ms/step - loss: 0.7825 - val_loss: 0.5244\n",
      "Epoch 2/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4797 - val_loss: 0.4893\n",
      "Epoch 3/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4465 - val_loss: 0.4648\n",
      "Epoch 4/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4315 - val_loss: 0.4601\n",
      "Epoch 5/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4219 - val_loss: 0.4500\n",
      "Epoch 6/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4162 - val_loss: 0.4586\n",
      "Epoch 7/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4123 - val_loss: 0.4441\n",
      "Epoch 8/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4074 - val_loss: 0.4659\n",
      "Epoch 9/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4048 - val_loss: 0.4481\n",
      "Epoch 10/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.4431\n",
      "Epoch 11/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3958 - val_loss: 0.4378\n",
      "Epoch 12/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3930 - val_loss: 0.4359\n",
      "Epoch 13/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3907 - val_loss: 0.4372\n",
      "Epoch 14/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3876 - val_loss: 0.4302\n",
      "Epoch 15/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3856 - val_loss: 0.4352\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "EPOCHS = 15\n",
    "VALIDAQTION_SET = [x_scaled_valid, y_valid]\n",
    "\n",
    "history1 = model_no_drop.fit(x_scaled_train, y_train,\n",
    "                 epochs=EPOCHS,\n",
    "                batch_size=36,\n",
    "                 validation_data=VALIDAQTION_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452877bf-15f9-49bb-8ccc-6ad00e8074a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab0b71aa-d0e3-4cf8-97f0-390c611d1f9f",
   "metadata": {},
   "source": [
    "## WITH DROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d6863ef-d637-4051-a44e-0a646e920d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS2 = [tf.keras.layers.Dense(30, activation=\"relu\", input_shape = x_train.shape[1:]),\n",
    "           tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "           tf.keras.layers.Dropout(0.2), \n",
    "           tf.keras.layers.Dense(1, activation=\"linear\"), \n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2f36237-6a3b-49db-adfc-7f55548933cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n",
    "\n",
    "model_drop = tf.keras.models.Sequential(LAYERS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bde609b-0ded-45b2-b836-aa621cf57941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compilation\n",
    "\n",
    "model_drop.compile(loss = LOSS,\n",
    "                  optimizer=OPTIMIZER,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4177ffc-7457-49e0-9afe-0ee4f0a1b7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.9409 - val_loss: 0.5593\n",
      "Epoch 2/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.6045 - val_loss: 0.4848\n",
      "Epoch 3/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.5517 - val_loss: 0.4779\n",
      "Epoch 4/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.5253 - val_loss: 0.4567\n",
      "Epoch 5/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.5062 - val_loss: 0.4535\n",
      "Epoch 6/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4954 - val_loss: 0.4488\n",
      "Epoch 7/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4876 - val_loss: 0.4502\n",
      "Epoch 8/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4756 - val_loss: 0.4446\n",
      "Epoch 9/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4658 - val_loss: 0.4496\n",
      "Epoch 10/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4631 - val_loss: 0.4453\n",
      "Epoch 11/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4543 - val_loss: 0.4474\n",
      "Epoch 12/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4496 - val_loss: 0.4452\n",
      "Epoch 13/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4446 - val_loss: 0.4404\n",
      "Epoch 14/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4450 - val_loss: 0.4458\n",
      "Epoch 15/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4405 - val_loss: 0.4422\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "\n",
    "history2 = model_drop.fit(x_scaled_train, y_train,\n",
    "                            epochs=EPOCHS,\n",
    "                            batch_size=36,\n",
    "                            validation_data=VALIDAQTION_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2413ec25-6a6c-45b0-b3d3-31abb51cc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## comparission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13c8bbdc-58c7-484b-91f3-3df20e26d26d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.782463</td>\n",
       "      <td>0.524436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.479736</td>\n",
       "      <td>0.489278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.446477</td>\n",
       "      <td>0.464766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.431489</td>\n",
       "      <td>0.460120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.421887</td>\n",
       "      <td>0.450012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.416170</td>\n",
       "      <td>0.458556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.412262</td>\n",
       "      <td>0.444082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.407376</td>\n",
       "      <td>0.465895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.404791</td>\n",
       "      <td>0.448113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.400386</td>\n",
       "      <td>0.443124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.395850</td>\n",
       "      <td>0.437817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.393007</td>\n",
       "      <td>0.435939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.390699</td>\n",
       "      <td>0.437186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.387554</td>\n",
       "      <td>0.430188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.385555</td>\n",
       "      <td>0.435156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  val_loss\n",
       "0   0.782463  0.524436\n",
       "1   0.479736  0.489278\n",
       "2   0.446477  0.464766\n",
       "3   0.431489  0.460120\n",
       "4   0.421887  0.450012\n",
       "5   0.416170  0.458556\n",
       "6   0.412262  0.444082\n",
       "7   0.407376  0.465895\n",
       "8   0.404791  0.448113\n",
       "9   0.400386  0.443124\n",
       "10  0.395850  0.437817\n",
       "11  0.393007  0.435939\n",
       "12  0.390699  0.437186\n",
       "13  0.387554  0.430188\n",
       "14  0.385555  0.435156"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history1.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a57f730a-9459-4dc3-9c65-71a71a591f01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.940858</td>\n",
       "      <td>0.559342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.604469</td>\n",
       "      <td>0.484779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.551706</td>\n",
       "      <td>0.477910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.525337</td>\n",
       "      <td>0.456676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.506181</td>\n",
       "      <td>0.453459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.495422</td>\n",
       "      <td>0.448830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.487602</td>\n",
       "      <td>0.450240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.475574</td>\n",
       "      <td>0.444640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.465798</td>\n",
       "      <td>0.449592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.463142</td>\n",
       "      <td>0.445347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.454335</td>\n",
       "      <td>0.447378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.449587</td>\n",
       "      <td>0.445203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.444643</td>\n",
       "      <td>0.440371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.444994</td>\n",
       "      <td>0.445810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.440491</td>\n",
       "      <td>0.442172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  val_loss\n",
       "0   0.940858  0.559342\n",
       "1   0.604469  0.484779\n",
       "2   0.551706  0.477910\n",
       "3   0.525337  0.456676\n",
       "4   0.506181  0.453459\n",
       "5   0.495422  0.448830\n",
       "6   0.487602  0.450240\n",
       "7   0.475574  0.444640\n",
       "8   0.465798  0.449592\n",
       "9   0.463142  0.445347\n",
       "10  0.454335  0.447378\n",
       "11  0.449587  0.445203\n",
       "12  0.444643  0.440371\n",
       "13  0.444994  0.445810\n",
       "14  0.440491  0.442172"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history2.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ca81c-175d-4a7b-bbab-c6c0634a0a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67970174-c895-438f-823e-70043590bfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4506\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4588\n"
     ]
    }
   ],
   "source": [
    "## compare th model loss for both model\n",
    "evaluation_drop_out = model_no_drop.evaluate(x_scaled_test, y_test)\n",
    "evaluation_drop = model_drop.evaluate(x_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "144cd056-4e4f-4fd8-b45d-3877fb327720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss without Drop-out: 45.06%\n",
      "loss with drop-out: 45.88%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation \n",
    "print(f\"loss without Drop-out: {evaluation_drop_out*100:.2f}%\")\n",
    "print(f\"loss with drop-out: {evaluation_drop*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daab176e-bf40-4f30-a8ac-d86e6e19a09b",
   "metadata": {},
   "source": [
    "## conclusion\n",
    "Here we can absorve that after appling drop-out regularization the loss function is get increased on test data, so in this cass this might be not very use full regularization for the model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe2542-fc19-414f-bb4a-c1f8b961d7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06a4b71d-ec49-4968-a3bf-e3189c17a6f9",
   "metadata": {},
   "source": [
    "\n",
    "Q2. Discuss the considerations and tradeoffs when choosing the appropriate regularization technique for a given deep learning task.\n",
    "\n",
    "Answer --> The choice of regularization technique should be guided by understanding of the problem, the characteristics of the data, and the model's complexity. Experimentation and validation on a holdout dataset or through cross-validation are crucial for determining the most effective regularization strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9052b33e-85ef-40a5-88df-c741ecb94da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0986f2d-f684-4e62-87fc-b99fcf567183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa27b84-332e-4446-91cc-3709bb0186dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
